# -*- coding: utf-8 -*-
"""spamdetection(maheshkumar).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10gCvOnNWphsUcn3zLIOb_pQm8wj0K2g0
"""

import numpy as np
import pandas as pd

df = pd.read_csv('spam.csv', encoding='ISO-8859-1')

df.sample(5)

df.shape

"""#**1.DATA CLEANING**

"""

df.info()

#clear last 3 cols
df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)

df.sample()

# renaming the cols
df.rename(columns={'v1':'target','v2':'text'},inplace=True)

from sklearn.preprocessing import LabelEncoder
encoder= LabelEncoder()

df['target']=encoder.fit_transform(df['target'])

df.head()

#check missing values
df.isnull().sum()

# check no of duplicate values
df.duplicated().sum()
#initially there were some values bu ti rerun it after removing dupliacates so they got removed

# remove duplicates
df.drop_duplicates(keep='first')

df.duplicated().sum()

df.shape



"""# **2.EDA(Exploratory Data Analysis)**"""

#check counts of ham/spam (0/1 in the target column)
df['target'].value_counts()

import matplotlib.pyplot as plt
plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct="%0.2f")
plt.show()

#after looking at pie chart we can see data is imbalanced
#now we are creating three new columns for deeper analysis
# by no of characters in the sms
# by no of words in the sms
# by no of sentences in the sms

import nltk
nltk.download('punkt')

# adding column by no of characters in the sms
df['num_characters']=df['text'].apply(len)

df.head()

# adding column by no of words in the sms

nltk.download('punkt_tab')
df['num_words'] = df['text'].apply(lambda x: len(nltk.word_tokenize(x)))

df.head()

# adding column by no of sentence in the sms
df['num_sentences'] = df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))

df.head()

#lets describe these three new columns for ham and spam differnetly

#first for ham(0)
df[df['target']==0][['num_characters','num_words','num_sentences']].describe()

#second for spam(1)
df[df['target']==1][['num_characters','num_words','num_sentences']].describe()

#AS WE CAN SEE USING ABOVE DATA THE MEAN LENGTH VARIES FOR BOTH
# SEE MORE USING HISTOGRAM

import seaborn as sns
sns.histplot(df[df['target']==0]['num_characters'])
sns.histplot(df[df['target']==1]['num_characters'],color="yellow")

sns.histplot(df[df['target']==0]['num_words'])
sns.histplot(df[df['target']==1]['num_words'],color="yellow")

sns.histplot(df[df['target']==0]['num_sentences'])
sns.histplot(df[df['target']==1]['num_sentences'],color="yellow")

#SO IT IS VISIBLE THAT HAM MESSAGES CONTAIN MORE WORDS,CHAR,SENT THAN SPAM MESSAGES

#LETS CHECK ORE USING CORRELATION COEFFICIENT OF THESE CHARACTERISTICS BETWEEN EACH OTHER

df.select_dtypes(include='number').corr()

#correlation using heatmap

sns.heatmap(df.select_dtypes(include='number').corr(),annot=True)

#SO WE CAN SE THAT TARGET IS MOSTLY DEPENDENT ON NUM CHAR WHERE CORR IS (0.39)
#SO IF WE WANT TO TAKE ONE AS A DECIDING COLUMN THEN WE WILL GO NUM_CHARATCERS(no of characters)

"""#**3.DATA PREPROCESSING**

*   lower case
*   tokenization
*   removing special characters(keep only alhpnum char)
*   removing stop words and punctuation
*   stemming(like dancing,dances,danced all equa to danc)




"""

# ❌ Not alphanumeric:
# These are non-alphanumeric characters:

# Punctuation: !, ., ?, @, ,

# Symbols: #, $, %, &

# Whitespace: space ( ), tab (\t), newline (\n)

#WE WILL BW DOING THESE STEPS USING A FUNCTION OVER A TEXT

#for stop words
from nltk.corpus import stopwords
nltk.download('stopwords')

#for punctuation
import string

#for stemming
from nltk.stem.porter import PorterStemmer

#function
def transform_text(text):
  text=text.lower() #lower case
  text=nltk.word_tokenize(text) #tokenization

  #removing special char(keeping only alphanumeric) ,removing stopwords, removing punctuatuion
  y=[]
  for i in text:
    if i.isalnum() and i not in stopwords.words('english') and i not in string.punctuation :
      y.append(i)

  text=y[:]
  y.clear()

  #stemming(always tokenize first)
  for i in text:
    y.append(ps.stem(i))

  #join them as a text (finally they shouldnt be as tokens)
  text= " ".join(y)
  return text

stopwords.words('english')

string.punctuation

ps =PorterStemmer()
ps.stem('dancing')

#check the function
transform_text('I loved the YT lectures on Machine Learning. How about you?')

#check at dataset
transform_text(df['text'][0])

df['transformed_text']=df['text'].apply(transform_text)

df.head()

#WORD CLOUD GIVES MOST USED WORDS
from wordcloud import WordCloud
wc= WordCloud(width=500,height=500,min_font_size=12,background_color='white')

#FOR SPAM MESSAGES
spam_wc=wc.generate(df[df['target']==1]['transformed_text'].str.cat(sep=" "))
plt.imshow(spam_wc)

#FOR HAM MESSAGES
ham_wc=wc.generate(df[df['target']==0]['transformed_text'].str.cat(sep=" "))
plt.imshow(spam_wc)

#TOP 30 WORDS IN SPAM MESSAGES
spam_corpus=[]
for msg in df[df['target']==1]['transformed_text'].tolist():
  for word in msg.split():
    spam_corpus.append(word)

len(spam_corpus)

from collections import Counter
top_spam_words = Counter(spam_corpus).most_common(30)

# Step 3: Convert to DataFrame
spam_df = pd.DataFrame(top_spam_words, columns=['word', 'frequency'])

# Step 4: Plot using Seaborn
plt.figure(figsize=(6,3))
sns.barplot(x='word', y='frequency', data=spam_df)
plt.xticks(rotation='vertical')
plt.title("Top 30 Words in Spam Messages")
plt.show()



#TOP 30 WORDS IN HAM MESSAGES
ham_corpus=[]
for msg in df[df['target']==0]['transformed_text'].tolist():
  for word in msg.split():
    ham_corpus.append(word)

    from collections import Counter
top_ham_words = Counter(ham_corpus).most_common(30)

# Step 3: Convert to DataFrame
ham_df = pd.DataFrame(top_ham_words, columns=['word', 'frequency'])

# Step 4: Plot using Seaborn
plt.figure(figsize=(6,3))
sns.barplot(x='word', y='frequency', data=ham_df)
plt.xticks(rotation='vertical')
plt.title("Top 30 Words in Ham Messages")
plt.show()

len(ham_corpus)



"""#**4.MODEL BUILDING**

"""

from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
cv=CountVectorizer()
tfidf=TfidfVectorizer()

# X = cv.fit_transform(df['transformed_text']).toarray()
X = tfidf.fit_transform(df['transformed_text']).toarray()

X.shape

y=df['target'].values

y

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)

from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB
from sklearn.metrics import accuracy_score,confusion_matrix,precision_score

gnb=GaussianNB()
mnb=MultinomialNB()
bnb=BernoulliNB()

#CHECK PRECISION SCORE FOR ALL THREE METHODS

"""| CONFUSION.    MATRIX | **Predicted: Ham (0)** | **Predicted: Spam (1)** |
| -------------------- | ---------------------- | ----------------------- |
| **Actual: Ham (0)**  | True Negative (TN)     | False Positive (FP)     |
| **Actual: Spam (1)** | False Negative (FN)    | True Positive (TP)      |

Accuracy = (TP + TN) / Total

Precision = TP / (TP + FP)

Recall = TP / (TP + FN)

F1 = 2 × (Precision × Recall) / (Precision + Recall)
"""

#for gaussian
gnb.fit(X_train,y_train)
y_pred1= gnb.predict(X_test)
print(accuracy_score(y_test,y_pred1))
print(confusion_matrix(y_test,y_pred1))
print(precision_score(y_test,y_pred1))

#for multinomial
mnb.fit(X_train,y_train)
y_pred2= mnb.predict(X_test)
print(accuracy_score(y_test,y_pred2))
print(confusion_matrix(y_test,y_pred2))
print(precision_score(y_test,y_pred2))

#for bernoullii
bnb.fit(X_train,y_train)
y_pred3= bnb.predict(X_test)
print(accuracy_score(y_test,y_pred3))
print(confusion_matrix(y_test,y_pred3))
print(precision_score(y_test,y_pred3))

#IMBALANCE DATA SO PRECISION SCORE(FALSE NEGATIVE SHOULD BE LEAST) MATTERS MOST THAT SHOULD BE HIGH
# --> SO WHILE APPLYING COUNTVECTORIZER WE GOT MAX PRECISION SCORE 0.992
#--> lets try it with  Tfidfvectorizer also

#SO FINALLLY AFTER APPLYING Tfidfvectorizer we got precision score 1 in multinomial bayes
#THIS STATE THAT WHILE USING MULTINOMIAL THERE WERE NO EMAIL WHICH WERE NOT SPAM AND WE CALLED IT SPAM
#SO WE WILL GO WITH MULTINOMIAL

# tfidf--> mnb

#WE GOT tfidf--> mnb precision sc 1 but lets check for all the models
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier

svc=SVC(kernel='sigmoid',gamma=1.0)
knc=KNeighborsClassifier()
mnb=MultinomialNB()
dtc=DecisionTreeClassifier(max_depth=5)
lrc=LogisticRegression(solver='liblinear',penalty='l1')
rfc=RandomForestClassifier(n_estimators=50,random_state=2)
abc=AdaBoostClassifier(n_estimators=50,random_state=2)
bc=BaggingClassifier(n_estimators=50,random_state=2)
etc=ExtraTreesClassifier(n_estimators=50,random_state=2)
gbdt=GradientBoostingClassifier(n_estimators=50,random_state=2)
xgb=XGBClassifier(n_estimators=50,random_state=2)

#create a dictionary for all classifir with keys and values
clfs = {
    'SVC': svc,
    'KN': knc,
    'NB': mnb,
    'DT': dtc,
    'LR': lrc,
    'RF': rfc,
    'AdaBoost': abc,
    'Bgc': bc,
    'ETC': etc,
    'GBDT': gbdt,
    'xgb': xgb
}

# a function that takes these classifiers as input and train and test x,y

def train_classifier(clf,X_train,y_train,X_test,y_test):
  clf.fit(X_train,y_train)
  y_pred=clf.predict(X_test)
  accuracy=accuracy_score(y_test,y_pred)
  precision=precision_score(y_test,y_pred)
  return accuracy,precision

train_classifier(svc,X_train,y_train,X_test,y_test)

#lets check for every algo using loop

accuracy_scores=[]
precision_scores=[]

for name,clf in clfs.items():

  current_accuracy,current_precision=train_classifier(clf,X_train,y_train,X_test,y_test)

  print("For ",name)
  print("Accuracy- ",current_accuracy)
  print("precision- ",current_precision)

  accuracy_scores.append(current_accuracy)
  precision_scores.append(current_precision)



   #this if for max_features

#lets create a dataframe comparing the scores

performance_df=pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precison':precision_scores}).sort_values('Precison',ascending=False)

performance_df

#NOW WE ARE CONSIDERING NB BUT WE CAN ALSO TAKE ETC
#by taking max_features=3000 accuracy of naive bayes also increased

"""#**4.MODEL IMPROVEMENT**"""

#WE CAN CHECK THE PRECISION AND ACCURACY BY ADDING ANOTHER METHODS LIKE
#TAKING MAX FEATURES=3000
#ADDING CHARACTER COLUMN TO VECTORIZER
#VOTING CLASSIFIER (MIXING MANY CLASSIFIER TO OBTAIN 1 )
#STACKING(SAME AS VOTING BY WE ADD WEIGHTAGE FOR EACH CLASSIFIER'S ALGO)

#IMPORTANT- WE TRIED MANY POSSIBILITIES TO OBTAIN BEST MODEL BUT THE FINAL WHICH GAVE BEST RESULT WAS
#NAIVE BAYES (MULTINOMIAL )

#NOW LETS PIPELINE THIS TO WEBSITE

#to take tfidf and mnb in a file and use them without training
import pickle
pickle.dump(tfidf,open('vectorizer.pkl','wb'))
pickle.dump(mnb,open('model.pkl','wb'))

#download these files
from google.colab import files
files.download('model.pkl')
files.download('vectorizer.pkl')

